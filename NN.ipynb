{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b18b53",
   "metadata": {},
   "source": [
    "# Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23fafb45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141b8bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class tanh:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        \n",
    "    def forward_pass(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return np.tanh(inputs)\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        return np.multiply(output_gradient, (1 - np.square(np.tanh(self.inputs))))\n",
    "\n",
    "class sigmoid:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        \n",
    "    def forward_pass(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        return np.reciprocal(1 + np.exp(-1 * inputs))\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        return np.multiply(output_gradient, np.multiply(np.reciprocal(1 + np.exp(-1 * self.inputs)), (1 - np.reciprocal(1 + np.exp(-1 * self.inputs)))))\n",
    "\n",
    "class softmax:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "        \n",
    "    def forward_pass(self, inputs):\n",
    "        s = np.sum(np.exp(inputs))\n",
    "        self.outputs = np.exp(inputs) / s\n",
    "        return self.outputs\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        n = np.size(output_gradient)\n",
    "        I = np.matrix(np.ones(n)).transpose()\n",
    "        return np.multiply(np.multiply(self.outputs, I - self.outputs), output_gradient)\n",
    "    \n",
    "class linear:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.inputs = None\n",
    "        self.outputs = None\n",
    "    \n",
    "    def forward_pass(self, inputs):\n",
    "        return inputs\n",
    "    \n",
    "    def backward_pass(self, output_gradient):\n",
    "        return output_gradient\n",
    "    \n",
    "class mse_loss:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Y_pred = None\n",
    "        self.outputs = None\n",
    "    \n",
    "    def forward_pass(self, Y_pred, Y):\n",
    "        self.Y_pred = Y_pred\n",
    "        self.Y = Y\n",
    "        #print(Y_pred.shape, Y.shape)\n",
    "        return np.sum(np.square(Y - Y_pred))/np.size(Y)\n",
    "    \n",
    "    def backward_pass(self):\n",
    "        out = 2 * (self.Y_pred - self.Y) / np.size(self.Y)\n",
    "        #print(out.shape)\n",
    "        return out\n",
    "        \n",
    "class cross_entropy_loss:\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.Y_pred = None\n",
    "        self.outputs = None\n",
    "        \n",
    "    def forward_pass(self, Y_pred, Y):\n",
    "        self.Y_pred = Y_pred\n",
    "        self.Y = Y\n",
    "        n = np.size(self.Y)\n",
    "        I = np.matrix(np.ones(n)).transpose()\n",
    "        return -np.sum(np.multiply(Y, np.log(Y_pred)) + np.multiply(I - Y, np.log(I - Y_pred)))\n",
    "    \n",
    "    def backward_pass(self):\n",
    "        n = np.size(self.Y)\n",
    "        I = np.matrix(np.ones(n)).transpose()\n",
    "        return (I - self.Y) / (I - self.Y_pred) - self.Y / self.Y_pred\n",
    "    \n",
    "    \n",
    "class makelayer:\n",
    "    \n",
    "    def __init__(self, in_neuron, out_neuron, activation):\n",
    "        self.activation = activation\n",
    "        self.in_neuron= in_neuron\n",
    "        self.out_neuron= out_neuron\n",
    "        self.w = np.matrix(np.random.randn(out_neuron, in_neuron))\n",
    "        self.b = np.matrix(np.random.randn(out_neuron)).transpose()\n",
    "\n",
    "    def forward_pass(self, inputs):\n",
    "        self.inputs = inputs\n",
    "        outputs = self.w @ inputs + self.b\n",
    "        return self.activation.forward_pass(outputs)\n",
    "    \n",
    "    def backward_pass(self, output_gradient, learning_rate = 0.01):\n",
    "        activation_gradient = self.activation.backward_pass(output_gradient)\n",
    "        w_gradient = activation_gradient @ self.inputs.transpose()\n",
    "        b_gradient = activation_gradient\n",
    "        self.w -= learning_rate * w_gradient\n",
    "        self.b -= learning_rate * b_gradient\n",
    "        input_gradient = self.w.transpose() @ activation_gradient\n",
    "        return input_gradient\n",
    "        \n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, X, Y, list_layers, loss, iteration = 2001, learning_rate = 0.01):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "        self.features = X[0].size\n",
    "        self.list_layers = list_layers\n",
    "        self.loss = loss\n",
    "        self.iteration = iteration\n",
    "        self.learning_rate = learning_rate\n",
    "    \n",
    "    def train(self):\n",
    "        self.train_layers_list = []\n",
    "        prev = self.features\n",
    "        for (output_neurons, activation) in self.list_layers:\n",
    "            self.train_layers_list.append(makelayer(prev, output_neurons, activation))\n",
    "            prev = output_neurons\n",
    "\n",
    "        for iter in range(self.iteration):\n",
    "            if iter%100==0:\n",
    "                print(\"iterations completed:\",iter)\n",
    "            for x, y in zip(self.X, self.Y):\n",
    "                #print(x,y)\n",
    "                y = y.transpose()\n",
    "                output = x.transpose()\n",
    "                #print(x,x.shape, output.shape)\n",
    "                for layer in self.train_layers_list:\n",
    "                    output = layer.forward_pass(output)\n",
    "                output = self.loss.forward_pass(output, y)\n",
    "\n",
    "                grad = self.loss.backward_pass()\n",
    "                #print(grad, grad.shape)\n",
    "                for layer in reversed(self.train_layers_list):\n",
    "                    grad = layer.backward_pass(grad, self.learning_rate)\n",
    "\n",
    "    def test(self, X_test):\n",
    "        outputs = []\n",
    "        for x in X_test:\n",
    "            output = x.transpose()\n",
    "            for layer in self.train_layers_list:\n",
    "                output = layer.forward_pass(output)\n",
    "            outputs.append(output.T.tolist()[0])\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1a54b",
   "metadata": {},
   "source": [
    "# Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5256ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2de7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_dataset.data\n",
    "Y = boston_dataset.target\n",
    "X = (X - X.min()) / (X.max() - X.min())\n",
    "Y = (Y - Y.min()) / (Y.max() - Y.min())\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9426cba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.matrix(X_train)\n",
    "X_test = np.matrix(X_test)\n",
    "Y_train = np.matrix(Y_train).T\n",
    "Y_test = np.matrix(Y_test).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da74724",
   "metadata": {},
   "source": [
    "## a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f4ecc527",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations completed: 0\n",
      "iterations completed: 100\n",
      "iterations completed: 200\n",
      "iterations completed: 300\n",
      "iterations completed: 400\n",
      "iterations completed: 500\n",
      "iterations completed: 600\n",
      "iterations completed: 700\n",
      "iterations completed: 800\n",
      "iterations completed: 900\n",
      "iterations completed: 1000\n",
      "iterations completed: 1100\n",
      "iterations completed: 1200\n",
      "iterations completed: 1300\n",
      "iterations completed: 1400\n",
      "iterations completed: 1500\n",
      "iterations completed: 1600\n",
      "iterations completed: 1700\n",
      "iterations completed: 1800\n",
      "iterations completed: 1900\n",
      "iterations completed: 2000\n"
     ]
    }
   ],
   "source": [
    "layers1 = [(1, linear())]\n",
    "NN1 = NeuralNetwork(X_train, Y_train, layers1, mse_loss())\n",
    "NN1.train()\n",
    "pred1 = np.matrix(NN1.test(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8b88220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.01608347590587703 \n",
      "Percentage Error: 31.808769139208888 %\n"
     ]
    }
   ],
   "source": [
    "mse1 = np.sum(np.square(Y_test - pred1))/Y_test.size\n",
    "p_error1 = 0\n",
    "for i in range(Y_test.size):\n",
    "    temp = Y_test.item(i)\n",
    "    if temp != 0:\n",
    "        p_error1 += abs(temp - pred1.item(i)) / temp\n",
    "p_error1 *= 100 / Y_test.size\n",
    "print(\"Mean Squared Error:\",mse1,\"\\nPercentage Error:\",p_error1,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d91fd61",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44638303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations completed: 0\n",
      "iterations completed: 100\n",
      "iterations completed: 200\n",
      "iterations completed: 300\n",
      "iterations completed: 400\n",
      "iterations completed: 500\n",
      "iterations completed: 600\n",
      "iterations completed: 700\n",
      "iterations completed: 800\n",
      "iterations completed: 900\n",
      "iterations completed: 1000\n",
      "iterations completed: 1100\n",
      "iterations completed: 1200\n",
      "iterations completed: 1300\n",
      "iterations completed: 1400\n",
      "iterations completed: 1500\n",
      "iterations completed: 1600\n",
      "iterations completed: 1700\n",
      "iterations completed: 1800\n",
      "iterations completed: 1900\n",
      "iterations completed: 2000\n"
     ]
    }
   ],
   "source": [
    "layers2 = [(13, sigmoid()), (1, linear())]\n",
    "NN2 = NeuralNetwork(X_train, Y_train, layers2, mse_loss())\n",
    "NN2.train()\n",
    "pred2 = np.matrix(NN2.test(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b7f2b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.015558959254216262 \n",
      "Percentage Error: 27.12910832380324 %\n"
     ]
    }
   ],
   "source": [
    "mse2 = np.sum(np.square(Y_test - pred2))/Y_test.size\n",
    "p_error2 = 0\n",
    "for i in range(Y_test.size):\n",
    "    temp = Y_test.item(i)\n",
    "    if temp != 0:\n",
    "        p_error2 += abs(temp - pred2.item(i)) / temp\n",
    "p_error2 *= 100 / Y_test.size\n",
    "print(\"Mean Squared Error:\",mse2,\"\\nPercentage Error:\",p_error2,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fcec73a",
   "metadata": {},
   "source": [
    "## c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "133394f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations completed: 0\n",
      "iterations completed: 100\n",
      "iterations completed: 200\n",
      "iterations completed: 300\n",
      "iterations completed: 400\n",
      "iterations completed: 500\n",
      "iterations completed: 600\n",
      "iterations completed: 700\n",
      "iterations completed: 800\n",
      "iterations completed: 900\n",
      "iterations completed: 1000\n",
      "iterations completed: 1100\n",
      "iterations completed: 1200\n",
      "iterations completed: 1300\n",
      "iterations completed: 1400\n",
      "iterations completed: 1500\n",
      "iterations completed: 1600\n",
      "iterations completed: 1700\n",
      "iterations completed: 1800\n",
      "iterations completed: 1900\n",
      "iterations completed: 2000\n"
     ]
    }
   ],
   "source": [
    "layers3 = [(13, sigmoid()), (13, sigmoid()), (1, linear())]\n",
    "NN3 = NeuralNetwork(X_train, Y_train, layers3, mse_loss())\n",
    "NN3.train()\n",
    "pred3 = np.matrix(NN3.test(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccd8d281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.015799280013729128 \n",
      "Percentage Error: 26.835279247506946 %\n"
     ]
    }
   ],
   "source": [
    "mse3 = np.sum(np.square(Y_test - pred3))/Y_test.size\n",
    "p_error3 = 0\n",
    "for i in range(Y_test.size):\n",
    "    temp = Y_test.item(i)\n",
    "    if temp != 0:\n",
    "        p_error3 += abs(temp - pred3.item(i)) / temp\n",
    "p_error3 *= 100 / Y_test.size\n",
    "print(\"Mean Squared Error:\",mse3,\"\\nPercentage Error:\",p_error3,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c927b1e9",
   "metadata": {},
   "source": [
    "# 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b666d476",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist_dataset = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e407acf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist_dataset.data\n",
    "Y = mnist_dataset.target\n",
    "X = X / 255\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4fe78a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y = np.zeros((Y_train.size,10))\n",
    "for i in range(Y_train.size):\n",
    "    new_Y[i][Y_train[i]] = 1\n",
    "Y_train = new_Y\n",
    "X_train = np.matrix(X_train)\n",
    "X_test = np.matrix(X_test)\n",
    "Y_train = np.matrix(Y_train)\n",
    "Y_test = np.matrix(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bfa52b",
   "metadata": {},
   "source": [
    "## a "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad71df75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations completed: 0\n",
      "iterations completed: 100\n",
      "iterations completed: 200\n",
      "iterations completed: 300\n",
      "iterations completed: 400\n",
      "iterations completed: 500\n",
      "iterations completed: 600\n",
      "iterations completed: 700\n",
      "iterations completed: 800\n"
     ]
    }
   ],
   "source": [
    "layers4 = [(89, tanh()), (10, sigmoid())]\n",
    "NN4 = NeuralNetwork(X_train, Y_train, layers4, mse_loss(), iteration = 801)\n",
    "NN4.train()\n",
    "pred4 = NN4.test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "163a8b4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 94.72222222222221\n"
     ]
    }
   ],
   "source": [
    "correct_num = Y_test.tolist()[0]\n",
    "pred_num = []\n",
    "correct_pred = 0\n",
    "for i in range(len(pred4)):\n",
    "    pred_num.append(pred4[i].index(max(pred4[i])))\n",
    "    if pred_num[i] == correct_num[i]:\n",
    "        correct_pred += 1\n",
    "print(\"Accuracy:\",(correct_pred / len(pred4)) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66bebfaf",
   "metadata": {},
   "source": [
    "## b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51ca696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterations completed: 0\n",
      "iterations completed: 100\n",
      "iterations completed: 200\n",
      "iterations completed: 300\n",
      "iterations completed: 400\n",
      "iterations completed: 500\n",
      "iterations completed: 600\n",
      "iterations completed: 700\n",
      "iterations completed: 800\n"
     ]
    }
   ],
   "source": [
    "layers5 = [(89, tanh()), (10, softmax())]\n",
    "NN5 = NeuralNetwork(X_train, Y_train, layers5, cross_entropy_loss(), iteration = 801)\n",
    "NN5.train()\n",
    "pred5 = NN5.test(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa4a17b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.5\n"
     ]
    }
   ],
   "source": [
    "correct_num = Y_test.tolist()[0]\n",
    "pred_num = []\n",
    "correct_pred = 0\n",
    "for i in range(len(pred5)):\n",
    "    pred_num.append(pred5[i].index(max(pred5[i])))\n",
    "    if pred_num[i] == correct_num[i]:\n",
    "        correct_pred += 1\n",
    "print(\"Accuracy:\",(correct_pred / len(pred5)) * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
